# -*- coding: utf-8 -*-
"""capstone2021_books.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/131g8CXdTkuT-z8QkZ71uctKfMy8V9DUj
"""

# from tensorflow.keras.datasets import mnist
# import matplotlib.pyplot as plt
# from keras.utils import np_utils
# from keras import Sequential
# from keras.layers import Dense
# import tensorflowjs as tfjs

import pandas as pd # dataframe library
import numpy as np # array libraray
import matplotlib.pyplot as plt # plots/graphs
import seaborn as sns # plots/graphs
import pickle

df = pd.read_csv("C:/Users/PUNEET SHARMA/Desktop/capstone_website/publishers.csv") # reading database into dataframe

df

#sns.pairplot(df)

df.info()

sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis') #nullvalues

df["genre"].unique()

# from sklearn.preprocessing import LabelEncoder
# le = LabelEncoder()
# dfle = df
# dfle['genre'] = le.fit_transform(dfle['genre'])
# dfle
genre_encoded = pd.get_dummies(df['genre'])
genre_encoded

df1 = pd.concat([df,genre_encoded] , axis = 1) #axis = 1 columnwise
df1.drop('publisher.name' , inplace=True , axis = 1)
df1

df1.drop(['daily average.amazon revenue' , 'daily average.author revenue' , 'daily average.publisher revenue' , 'daily average.units sold'] , inplace = True , axis = 1)

df1.drop(['genre'] , axis = 1 , inplace = True)

sold_by_encoded = pd.get_dummies(df1['sold by'])
df2 = pd.concat([df1,sold_by_encoded] , axis = 1)
df2.drop(['sold by'] , inplace = True , axis = 1)
df2

df2['publisher.type'].nunique() #unique values

pub_type_encoded = pd.get_dummies(df2['publisher.type'])
df3 = pd.concat([df2,pub_type_encoded] , axis = 1)
df3.drop(['publisher.type'] , inplace = True , axis = 1)
df3

#df3.drop('statistics.sales rank' , axis = 1 , inplace = True)
from sklearn.linear_model import LinearRegression
linear = LinearRegression()
X = df3.drop('daily average.gross sales' , axis = 1)
y = df3['daily average.gross sales']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25 , random_state = 42)

linear.fit(X_train,y_train)

predictions = linear.predict(X_test)

from sklearn import metrics

print('MAE:', metrics.mean_absolute_error(y_test, predictions))
print('MSE:', metrics.mean_squared_error(y_test, predictions))
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))

predictions_t = linear.predict(X_train)
print('MAE:', metrics.mean_absolute_error(y_train, predictions_t))
print('MSE:', metrics.mean_squared_error(y_train, predictions_t))
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_train, predictions_t)))

predictions.max()
y_test.max()

filename = 'finalized_model.sav'
pickle.dump(linear, open(filename, 'wb'))


